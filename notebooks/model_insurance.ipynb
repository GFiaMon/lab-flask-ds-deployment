{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89cdd586",
   "metadata": {},
   "source": [
    "# Train and Save a Model for Flask Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e4f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports\n",
    "\n",
    "# Add project root to path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96df9726",
   "metadata": {},
   "source": [
    "## 1. Load and prepare data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f3d884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "df = pd.read_csv('../data/insurance.csv')\n",
    "\n",
    "# Remove duplicate\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Feature engineering\n",
    "def prepare_features(df):\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Create BMI categories\n",
    "    df_processed['bmi_category'] = pd.cut(df_processed['bmi'], \n",
    "                                        bins=[0, 18.5, 25, 30, 100], \n",
    "                                        labels=['underweight', 'normal', 'overweight', 'obese'])\n",
    "    \n",
    "    # Create age groups\n",
    "    df_processed['age_group'] = pd.cut(df_processed['age'], \n",
    "                                     bins=[0, 30, 45, 60, 100], \n",
    "                                     labels=['young', 'adult', 'middle_aged', 'senior'])\n",
    "    \n",
    "    # Interaction features\n",
    "    df_processed['smoker_age_interaction'] = df_processed['smoker'].map({'yes': 1, 'no': 0}) * df_processed['age']\n",
    "    df_processed['smoker_bmi_interaction'] = df_processed['smoker'].map({'yes': 1, 'no': 0}) * df_processed['bmi']\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# Apply feature engineering\n",
    "df_processed = prepare_features(df)\n",
    "\n",
    "# Define features and target\n",
    "X = df_processed.drop('charges', axis=1)\n",
    "y = df_processed['charges']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e0f8546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define preprocessing for numerical and categorical features\n",
    "numerical_features = ['age', 'bmi', 'children']\n",
    "categorical_features = ['sex', 'smoker', 'region', 'bmi_category', 'age_group']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create pipeline with Random Forest\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Define parameter grid for the winning model configuration\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100],\n",
    "    'model__max_depth': [20],\n",
    "    'model__min_samples_split': [2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fdf65f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c2ac19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL MODEL RESULTS ===\n",
      "Best CV R²: 0.8296\n",
      "Test R²: 0.8655\n",
      "Best parameters: {'model__max_depth': 20, 'model__min_samples_split': 2, 'model__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(f\"=== FINAL MODEL RESULTS ===\")\n",
    "print(f\"Best CV R²: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Test R²: {test_r2:.4f}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e3e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL SAVED ===\n",
      "insurance_model.pkl - The trained model\n",
      "model_info.pkl - Model metadata and feature information\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model using pickle\n",
    "pickle.dump(best_model, open('../models/insurance_model.pkl', 'wb'))\n",
    "\n",
    "# Save model info\n",
    "model_info = {\n",
    "    'feature_names': list(X.columns),\n",
    "    'numerical_features': numerical_features,\n",
    "    'categorical_features': categorical_features,\n",
    "    'test_r2': test_r2,\n",
    "    'best_params': grid_search.best_params_\n",
    "}\n",
    "\n",
    "pickle.dump(model_info, open('../models/model_info.pkl', 'wb'))\n",
    "\n",
    "print(\"\\n=== MODEL SAVED ===\")\n",
    "print(\"insurance_model.pkl - The trained model\")\n",
    "print(\"model_info.pkl - Model metadata and feature information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a798274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction function for Flask\n",
    "def prepare_prediction_features(input_data, model, model_info):\n",
    "    \"\"\"\n",
    "    Prepare features for prediction in Flask app\n",
    "    \n",
    "    Args:\n",
    "        input_data: Dictionary with input features\n",
    "        model: Trained model pipeline\n",
    "        model_info: Model metadata\n",
    "    \n",
    "    Returns:\n",
    "        prediction: Model prediction\n",
    "    \"\"\"\n",
    "    # Convert input data to DataFrame\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "    \n",
    "    # Apply the same feature engineering\n",
    "    input_df = prepare_features(input_df)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(input_df)[0]\n",
    "    \n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98532d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SAMPLE PREDICTION ===\n",
      "Input: {'age': 35, 'sex': 'male', 'bmi': 28.5, 'children': 2, 'smoker': 'no', 'region': 'southeast'}\n",
      "Predicted charges: $11687.23\n"
     ]
    }
   ],
   "source": [
    "# Test the prediction function\n",
    "sample_input = {\n",
    "    'age': 35,\n",
    "    'sex': 'male',\n",
    "    'bmi': 28.5,\n",
    "    'children': 2,\n",
    "    'smoker': 'no',\n",
    "    'region': 'southeast'\n",
    "}\n",
    "\n",
    "loaded_model = pickle.load(open('../models/insurance_model.pkl', 'rb'))\n",
    "loaded_model_info = pickle.load(open('../models/model_info.pkl', 'rb'))\n",
    "\n",
    "sample_prediction = prepare_prediction_features(sample_input, loaded_model, loaded_model_info)\n",
    "print(f\"\\n=== SAMPLE PREDICTION ===\")\n",
    "print(f\"Input: {sample_input}\")\n",
    "print(f\"Predicted charges: ${sample_prediction:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28774732",
   "metadata": {},
   "source": [
    "-------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
